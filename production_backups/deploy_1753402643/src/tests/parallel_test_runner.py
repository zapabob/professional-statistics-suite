#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Parallel Test Runner
ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 

Author: Ryo Minegishi
Email: r.minegishi1987@gmail.com
License: MIT
"""

import asyncio
import multiprocessing
import subprocess
import sys
import os
from typing import Dict, List, Any, Optional
from pathlib import Path
import json
import logging
from datetime import datetime
import time
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import threading
from dataclasses import dataclass, field

@dataclass
class ParallelTestConfig:
    """ä¸¦åˆ—ãƒ†ã‚¹ãƒˆè¨­å®š"""
    max_workers: int = field(default_factory=lambda: min(multiprocessing.cpu_count(), 8))
    test_timeout: int = 300  # 5åˆ†
    retry_failed: bool = True
    max_retries: int = 3
    split_by: str = "file"  # file, class, function
    load_scope: str = "session"  # session, module, class, function
    auto_mode: bool = True
    debug: bool = False

@dataclass
class TestExecutionResult:
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœ"""
    test_name: str
    worker_id: int
    success: bool
    execution_time: float
    output: str
    error: Optional[str] = None
    retry_count: int = 0
    timestamp: datetime = field(default_factory=datetime.now)

class ParallelTestRunner:
    """ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: ParallelTestConfig = None):
        self.config = config or ParallelTestConfig()
        self.logger = logging.getLogger(__name__)
        self.results: List[TestExecutionResult] = []
        self.workers: List[Dict] = []
        
    def setup_workers(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®š"""
        self.logger.info(f"ğŸ”§ {self.config.max_workers}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’è¨­å®šä¸­...")
        
        for i in range(self.config.max_workers):
            worker = {
                "id": i,
                "status": "idle",
                "current_test": None,
                "start_time": None,
                "results": []
            }
            self.workers.append(worker)
        
        self.logger.info(f"âœ… {len(self.workers)}å€‹ã®ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®šå®Œäº†")
    
    def discover_tests(self, test_path: str = "src/tests") -> List[str]:
        """ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹"""
        test_files = []
        test_path_obj = Path(test_path)
        
        if test_path_obj.exists():
            for test_file in test_path_obj.rglob("test_*.py"):
                test_files.append(str(test_file))
        
        self.logger.info(f"ğŸ“ ç™ºè¦‹ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {len(test_files)}ä»¶")
        return test_files
    
    def split_tests_by_file(self, test_files: List[str]) -> List[List[str]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã§ãƒ†ã‚¹ãƒˆã‚’åˆ†å‰²"""
        chunks = []
        chunk_size = max(1, len(test_files) // self.config.max_workers)
        
        for i in range(0, len(test_files), chunk_size):
            chunk = test_files[i:i + chunk_size]
            chunks.append(chunk)
        
        self.logger.info(f"ğŸ“¦ ãƒ†ã‚¹ãƒˆã‚’{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²")
        return chunks
    
    def split_tests_by_class(self, test_files: List[str]) -> List[List[str]]:
        """ã‚¯ãƒ©ã‚¹å˜ä½ã§ãƒ†ã‚¹ãƒˆã‚’åˆ†å‰²"""
        # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¯ãƒ©ã‚¹ã‚’æŠ½å‡º
        test_classes = []
        
        for test_file in test_files:
            try:
                with open(test_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’æ¤œç´¢
                import re
                class_pattern = r'class\s+(\w+Test\w*)\s*[:\(]'
                classes = re.findall(class_pattern, content)
                
                for class_name in classes:
                    test_classes.append(f"{test_file}::{class_name}")
                    
            except Exception as e:
                self.logger.warning(f"ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« '{test_file}' ã®è§£æã‚¨ãƒ©ãƒ¼: {e}")
        
        return self.split_tests_by_file(test_classes)
    
    def execute_test_chunk(self, worker_id: int, test_chunk: List[str]) -> List[TestExecutionResult]:
        """ãƒ†ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã‚’å®Ÿè¡Œ"""
        results = []
        
        for test_file in test_chunk:
            try:
                self.logger.info(f"ğŸ”§ ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {test_file} ã‚’å®Ÿè¡Œä¸­...")
                
                start_time = time.time()
                
                # pytestã‚³ãƒãƒ³ãƒ‰ã‚’æ§‹ç¯‰
                cmd = [
                    sys.executable, "-m", "pytest",
                    test_file,
                    "-v",
                    "--tb=short",
                    "--no-header",
                    "--no-summary"
                ]
                
                if self.config.debug:
                    cmd.append("--capture=no")
                
                # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                process = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=self.config.test_timeout
                )
                
                execution_time = time.time() - start_time
                
                # çµæœã‚’è§£æ
                success = process.returncode == 0
                output = process.stdout
                error = process.stderr if not success else None
                
                result = TestExecutionResult(
                    test_name=test_file,
                    worker_id=worker_id,
                    success=success,
                    execution_time=execution_time,
                    output=output,
                    error=error
                )
                
                results.append(result)
                
                if success:
                    self.logger.info(f"âœ… ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {test_file} æˆåŠŸ ({execution_time:.2f}ç§’)")
                else:
                    self.logger.error(f"âŒ ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {test_file} å¤±æ•— ({execution_time:.2f}ç§’)")
                
            except subprocess.TimeoutExpired:
                self.logger.error(f"â° ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {test_file} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                result = TestExecutionResult(
                    test_name=test_file,
                    worker_id=worker_id,
                    success=False,
                    execution_time=self.config.test_timeout,
                    output="",
                    error="Test timeout"
                )
                results.append(result)
                
            except Exception as e:
                self.logger.error(f"ğŸ’¥ ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {test_file} å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                result = TestExecutionResult(
                    test_name=test_file,
                    worker_id=worker_id,
                    success=False,
                    execution_time=0,
                    output="",
                    error=str(e)
                )
                results.append(result)
        
        return results
    
    async def run_parallel_tests(self, test_path: str = "src/tests") -> Dict:
        """ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("ğŸš€ ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹")
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼è¨­å®š
        self.setup_workers()
        
        # ãƒ†ã‚¹ãƒˆç™ºè¦‹
        test_files = self.discover_tests(test_path)
        
        if not test_files:
            self.logger.warning("âš ï¸ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {"error": "ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
        
        # ãƒ†ã‚¹ãƒˆåˆ†å‰²
        if self.config.split_by == "class":
            test_chunks = self.split_tests_by_class(test_files)
        else:
            test_chunks = self.split_tests_by_file(test_files)
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers) as executor:
            # å„ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            future_to_chunk = {
                executor.submit(self.execute_test_chunk, i, chunk): i
                for i, chunk in enumerate(test_chunks)
            }
            
            # çµæœã‚’åé›†
            for future in future_to_chunk:
                worker_id = future_to_chunk[future]
                try:
                    chunk_results = future.result()
                    self.results.extend(chunk_results)
                except Exception as e:
                    self.logger.error(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id} ã‚¨ãƒ©ãƒ¼: {e}")
        
        total_time = time.time() - start_time
        
        # çµæœé›†è¨ˆ
        summary = self.generate_summary(total_time)
        
        self.logger.info(f"âœ… ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå®Œäº†: {total_time:.2f}ç§’")
        
        return {
            "summary": summary,
            "results": [r.__dict__ for r in self.results],
            "workers": self.workers
        }
    
    def generate_summary(self, total_time: float) -> Dict:
        """çµæœã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        total_tests = len(self.results)
        successful_tests = sum(1 for r in self.results if r.success)
        failed_tests = total_tests - successful_tests
        
        total_execution_time = sum(r.execution_time for r in self.results)
        average_execution_time = total_execution_time / total_tests if total_tests > 0 else 0
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥çµ±è¨ˆ
        worker_stats = {}
        for worker in self.workers:
            worker_results = [r for r in self.results if r.worker_id == worker["id"]]
            worker_stats[worker["id"]] = {
                "total_tests": len(worker_results),
                "successful_tests": sum(1 for r in worker_results if r.success),
                "total_time": sum(r.execution_time for r in worker_results)
            }
        
        return {
            "total_tests": total_tests,
            "successful_tests": successful_tests,
            "failed_tests": failed_tests,
            "success_rate": (successful_tests / total_tests * 100) if total_tests > 0 else 0,
            "total_execution_time": total_execution_time,
            "average_execution_time": average_execution_time,
            "parallel_execution_time": total_time,
            "speedup_factor": total_execution_time / total_time if total_time > 0 else 1,
            "worker_stats": worker_stats,
            "max_workers": self.config.max_workers
        }
    
    def save_results(self, output_file: str = "parallel_test_results.json"):
        """çµæœã‚’ä¿å­˜"""
        try:
            results_data = {
                "timestamp": datetime.now().isoformat(),
                "config": self.config.__dict__,
                "summary": self.generate_summary(0),
                "results": [r.__dict__ for r in self.results]
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"âœ… çµæœã‚’ä¿å­˜: {output_file}")
            
        except Exception as e:
            self.logger.error(f"âŒ çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

class PytestXdistRunner:
    """pytest-xdistã‚’ä½¿ç”¨ã—ãŸä¸¦åˆ—å®Ÿè¡Œ"""
    
    def __init__(self, max_workers: int = None):
        self.max_workers = max_workers or min(multiprocessing.cpu_count(), 8)
        self.logger = logging.getLogger(__name__)
    
    def run_with_xdist(self, test_path: str = "src/tests", additional_args: List[str] = None) -> Dict:
        """pytest-xdistã‚’ä½¿ç”¨ã—ã¦ä¸¦åˆ—å®Ÿè¡Œ"""
        self.logger.info(f"ğŸš€ pytest-xdistã§ä¸¦åˆ—å®Ÿè¡Œé–‹å§‹ (ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°: {self.max_workers})")
        
        # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
        cmd = [
            sys.executable, "-m", "pytest",
            test_path,
            "-n", str(self.max_workers),  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
            "--dist", "loadfile",  # ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã§åˆ†æ•£
            "--tb=short",
            "-v",
            "--junitxml=test-results.xml"
        ]
        
        if additional_args:
            cmd.extend(additional_args)
        
        self.logger.info(f"ğŸ”§ å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
        
        start_time = time.time()
        
        try:
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=1800  # 30åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            execution_time = time.time() - start_time
            
            # çµæœè§£æ
            success = process.returncode == 0
            output = process.stdout
            error = process.stderr
            
            # JUnit XMLçµæœã‚’è§£æ
            junit_results = self.parse_junit_xml("test-results.xml")
            
            return {
                "success": success,
                "execution_time": execution_time,
                "output": output,
                "error": error,
                "junit_results": junit_results,
                "max_workers": self.max_workers
            }
            
        except subprocess.TimeoutExpired:
            self.logger.error("â° ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return {
                "success": False,
                "execution_time": 1800,
                "output": "",
                "error": "Test execution timeout",
                "max_workers": self.max_workers
            }
        
        except Exception as e:
            self.logger.error(f"ğŸ’¥ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "execution_time": 0,
                "output": "",
                "error": str(e),
                "max_workers": self.max_workers
            }
    
    def parse_junit_xml(self, xml_file: str) -> Dict:
        """JUnit XMLçµæœã‚’è§£æ"""
        try:
            import xml.etree.ElementTree as ET
            
            if not Path(xml_file).exists():
                return {"error": "JUnit XMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæƒ…å ±ã‚’æŠ½å‡º
            testsuite = root.find("testsuite")
            if testsuite is None:
                return {"error": "ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            return {
                "name": testsuite.get("name", ""),
                "tests": int(testsuite.get("tests", 0)),
                "errors": int(testsuite.get("errors", 0)),
                "failures": int(testsuite.get("failures", 0)),
                "skipped": int(testsuite.get("skipped", 0)),
                "time": float(testsuite.get("time", 0))
            }
            
        except Exception as e:
            self.logger.warning(f"JUnit XMLè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    
    # è¨­å®š
    config = ParallelTestConfig(
        max_workers=4,
        test_timeout=300,
        retry_failed=True,
        debug=True
    )
    
    # ä¸¦åˆ—ãƒ†ã‚¹ãƒˆãƒ©ãƒ³ãƒŠãƒ¼
    runner = ParallelTestRunner(config)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    async def run_tests():
        results = await runner.run_parallel_tests()
        
        # çµæœè¡¨ç¤º
        print("\n" + "="*50)
        print("ğŸ“Š ä¸¦åˆ—ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœ")
        print("="*50)
        
        if "error" in results:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {results['error']}")
            return
        
        summary = results["summary"]
        print(f"âœ… ç·ãƒ†ã‚¹ãƒˆæ•°: {summary['total_tests']}")
        print(f"âœ… æˆåŠŸãƒ†ã‚¹ãƒˆæ•°: {summary['successful_tests']}")
        print(f"âŒ å¤±æ•—ãƒ†ã‚¹ãƒˆæ•°: {summary['failed_tests']}")
        print(f"ğŸ“ˆ æˆåŠŸç‡: {summary['success_rate']:.1f}%")
        print(f"â±ï¸ ç·å®Ÿè¡Œæ™‚é–“: {summary['total_execution_time']:.2f}ç§’")
        print(f"âš¡ ä¸¦åˆ—å®Ÿè¡Œæ™‚é–“: {summary['parallel_execution_time']:.2f}ç§’")
        print(f"ğŸš€ é«˜é€ŸåŒ–ç‡: {summary['speedup_factor']:.2f}x")
        
        # ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥çµ±è¨ˆ
        print(f"\nğŸ”§ ãƒ¯ãƒ¼ã‚«ãƒ¼åˆ¥çµ±è¨ˆ:")
        for worker_id, stats in summary["worker_stats"].items():
            print(f"  ãƒ¯ãƒ¼ã‚«ãƒ¼ {worker_id}: {stats['total_tests']}ãƒ†ã‚¹ãƒˆ, {stats['successful_tests']}æˆåŠŸ, {stats['total_time']:.2f}ç§’")
    
    # éåŒæœŸå®Ÿè¡Œ
    asyncio.run(run_tests())

if __name__ == "__main__":
    main() 