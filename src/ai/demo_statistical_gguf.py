#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
GGUFçµ±è¨ˆè§£æãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
ãƒ­ãƒ¼ã‚«ãƒ«GGUFãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸçµ±è¨ˆè§£æAIã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢
"""

import sys
import time

# è¨­å®šã¨ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
try:
    from config import check_feature_permission
    if not check_feature_permission('advanced_ai'):
        print("âŒ Advanced AIæ©Ÿèƒ½ã«ã¯Professionalç‰ˆä»¥ä¸ŠãŒå¿…è¦ã§ã™")
        sys.exit(1)
except ImportError:
    print("âš ï¸ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ï¼ˆé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼‰".encode('utf-8').decode(sys.stdout.encoding, 'ignore'))

# AIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from src.ai.ai_integration import AIStatisticalAnalyzer

# ã‚¹ã‚¿ãƒ–é–¢æ•°ï¼ˆgguf_test_helperã®ä»£æ›¿ï¼‰
def setup_gguf_test_environment():
    return {
        'skip_tests': True,
        'error': 'GGUF test helper not available',
        'model_path': None
    }

def create_test_queries():
    return ["åŸºæœ¬çš„ãªçµ±è¨ˆè³ªå•"]

def create_statistical_context():
    return {
        'dataset_info': 'ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ',
        'analysis_goal': 'æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æ'
    }

def validate_gguf_response(response):
    return {'score': 50}

def print_test_summary(env):
    print("GGUF test environment summary")

def demonstrate_gguf_integration():
    """GGUFçµ±åˆæ©Ÿèƒ½ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸš€ GGUFçµ±è¨ˆè§£æAIã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    # 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    print("\nğŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—")
    test_env = setup_gguf_test_environment()
    
    if test_env['skip_tests']:
        print(f"âŒ {test_env['error']}")
        print("\nğŸ’¡ è§£æ±ºæ–¹æ³•:")
        print("   1. GGUFãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ ./models/ ã«é…ç½®")
        print("   2. ç’°å¢ƒå¤‰æ•° GGUF_MODEL_PATH ã‚’è¨­å®š")
        print("   3. llama-cpp-python ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install llama-cpp-python")
        return False
    
    print_test_summary(test_env)
    
    # 2. AIStatisticalAnalyzeråˆæœŸåŒ–
    print("\nğŸ§  Step 2: AIçµ±è¨ˆè§£æå™¨ã®åˆæœŸåŒ–")
    try:
        analyzer = AIStatisticalAnalyzer(gguf_model_path=test_env['model_path'])
        
        if 'gguf' in analyzer.providers:
            print("âœ… GGUFãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–æˆåŠŸ")
            print(f"ğŸ“Š ç¾åœ¨ã®ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {analyzer.current_provider}")
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º
            gguf_provider = analyzer.providers['gguf']
            model_info = gguf_provider.get_model_info()
            print(f"ğŸ”§ GPUæœ‰åŠ¹: {model_info['gpu_enabled']}")
            print(f"ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚µã‚¤ã‚º: {model_info['context_size']}")
        else:
            print("âŒ GGUFãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–å¤±æ•—")
            return False
            
    except Exception as e:
        print(f"âŒ AIçµ±è¨ˆè§£æå™¨åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # 3. åŸºæœ¬çš„ãªçµ±è¨ˆè³ªå•
    print("\nğŸ“Š Step 3: åŸºæœ¬çš„ãªçµ±è¨ˆè³ªå•")
    basic_questions = [
        "å¹³å‡ã¨ä¸­å¤®å€¤ã®é•ã„ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "tæ¤œå®šã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ç›¸é–¢ä¿‚æ•°ã®è§£é‡ˆæ–¹æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    ]
    
    for i, question in enumerate(basic_questions, 1):
        print(f"\nğŸ” è³ªå• {i}: {question}")
        
        start_time = time.time()
        result = analyzer.analyze_statistical_question(question)
        processing_time = time.time() - start_time
        
        if result['success']:
            print("âœ… å›ç­”ç”ŸæˆæˆåŠŸ")
            print(f"â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
            print(f"ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³æ¶ˆè²»: {result['tokens_consumed']}")
            print(f"ğŸ“ å›ç­”:\n{result['response'][:200]}...")
            
            # å¿œç­”å“è³ªè©•ä¾¡
            validation = validate_gguf_response(result['response'])
            print(f"ğŸ“Š å“è³ªã‚¹ã‚³ã‚¢: {validation['score']}/100")
            
        else:
            print(f"âŒ å›ç­”ç”Ÿæˆå¤±æ•—: {result['error']}")
    
    # 4. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãè§£æ
    print("\nğŸ¯ Step 4: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä»˜ãçµ±è¨ˆè§£æ")
    context = create_statistical_context()
    contextual_question = "ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«é©ã—ãŸçµ±è¨ˆæ‰‹æ³•ã‚’æ¨å¥¨ã—ã¦ãã ã•ã„ã€‚"
    
    print(f"ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±: {context['dataset_info']}")
    print(f"ğŸ¯ è§£æç›®æ¨™: {context['analysis_goal']}")
    print(f"ğŸ” è³ªå•: {contextual_question}")
    
    start_time = time.time()
    result = analyzer.analyze_statistical_question(contextual_question, context)
    processing_time = time.time() - start_time
    
    if result['success']:
        print("âœ… ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè§£ææˆåŠŸ")
        print(f"â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
        print(f"ğŸ“ æ¨å¥¨æ‰‹æ³•:\n{result['response'][:300]}...")
    else:
        print(f"âŒ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè§£æå¤±æ•—: {result['error']}")
    
    # 5. æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    print("\nâš¡ Step 5: æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
    test_queries = create_test_queries()
    
    # æœ€åˆã®5ã¤ã®ã‚¯ã‚¨ãƒªã§ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    benchmark_queries = dict(list(test_queries.items())[:5])
    
    total_time = 0
    total_tokens = 0
    successful_queries = 0
    
    for query_name, query_text in benchmark_queries.items():
        print(f"ğŸ”„ å®Ÿè¡Œä¸­: {query_name}")
        
        start_time = time.time()
        result = analyzer.analyze_statistical_question(query_text)
        query_time = time.time() - start_time
        
        if result['success']:
            successful_queries += 1
            total_time += query_time
            total_tokens += result['tokens_consumed']
            print(f"   âœ… æˆåŠŸ ({query_time:.2f}ç§’)")
        else:
            print(f"   âŒ å¤±æ•—: {result['error']}")
    
    if successful_queries > 0:
        avg_time = total_time / successful_queries
        avg_tokens = total_tokens / successful_queries
        
        print("\nğŸ“ˆ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ:")
        print(f"   æˆåŠŸç‡: {successful_queries}/{len(benchmark_queries)} ({successful_queries/len(benchmark_queries)*100:.1f}%)")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_time:.2f}ç§’")
        print(f"   å¹³å‡ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {avg_tokens:.0f}")
        print(f"   ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
    
    # 6. é«˜åº¦ãªçµ±è¨ˆè§£æã‚·ãƒŠãƒªã‚ª
    print("\nğŸ“ Step 6: é«˜åº¦ãªçµ±è¨ˆè§£æã‚·ãƒŠãƒªã‚ª")
    advanced_scenarios = [
        {
            "scenario": "å®Ÿé¨“è¨ˆç”»æ³•",
            "question": "2è¦å› ã®åˆ†æ•£åˆ†æã‚’å®Ÿè¡Œã™ã‚‹éš›ã®å‰ææ¡ä»¶ã¨è§£é‡ˆæ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
            "context": {
                "analysis_type": "experimental_design",
                "factors": 2,
                "dependent_variable": "continuous"
            }
        },
        {
            "scenario": "æ©Ÿæ¢°å­¦ç¿’çµ±è¨ˆ",
            "question": "å›å¸°åˆ†æã«ãŠã‘ã‚‹å¤šé‡å…±ç·šæ€§ã®å•é¡Œã¨å¯¾å‡¦æ³•ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
            "context": {
                "analysis_type": "regression",
                "problem": "multicollinearity",
                "data_type": "observational"
            }
        }
    ]
    
    for scenario in advanced_scenarios:
        print(f"\nğŸ”¬ ã‚·ãƒŠãƒªã‚ª: {scenario['scenario']}")
        print(f"â“ è³ªå•: {scenario['question']}")
        
        start_time = time.time()
        result = analyzer.analyze_statistical_question(
            scenario['question'], 
            scenario['context']
        )
        processing_time = time.time() - start_time
        
        if result['success']:
            print("âœ… é«˜åº¦è§£ææˆåŠŸ")
            print(f"â±ï¸  å‡¦ç†æ™‚é–“: {processing_time:.2f}ç§’")
            print(f"ğŸ“ å°‚é–€çš„å›ç­”:\n{result['response'][:250]}...")
            
            # å°‚é–€æ€§è©•ä¾¡
            validation = validate_gguf_response(result['response'])
            statistical_terms = validation['details'].get('statistical_terms', [])
            print(f"ğŸ¯ çµ±è¨ˆç”¨èªæ•°: {len(statistical_terms)}")
            print(f"ğŸ“Š å°‚é–€æ€§ã‚¹ã‚³ã‚¢: {validation['score']}/100")
        else:
            print(f"âŒ é«˜åº¦è§£æå¤±æ•—: {result['error']}")
    
    print("\nğŸ‰ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
    print("=" * 60)
    
    return True

def interactive_gguf_session():
    """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªGGUFçµ±è¨ˆè§£æã‚»ãƒƒã‚·ãƒ§ãƒ³"""
    print("\nğŸ® ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰é–‹å§‹")
    print("çµ±è¨ˆå­¦ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆ'quit'ã§çµ‚äº†ï¼‰")
    print("-" * 50)
    
    # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
    test_env = setup_gguf_test_environment()
    if test_env['skip_tests']:
        print(f"âŒ {test_env['error']}")
        return
    
    # AIè§£æå™¨åˆæœŸåŒ–
    try:
        analyzer = AIStatisticalAnalyzer(gguf_model_path=test_env['model_path'])
        if 'gguf' not in analyzer.providers:
            print("âŒ GGUFãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    session_count = 0
    
    while True:
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
            question = input(f"\n[{session_count + 1}] çµ±è¨ˆè³ªå•> ").strip()
            
            if question.lower() in ['quit', 'exit', 'çµ‚äº†', 'q']:
                print("ğŸ‘‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†")
                break
            
            if not question:
                continue
            
            # è³ªå•å‡¦ç†
            print("ğŸ¤” è€ƒãˆä¸­...")
            start_time = time.time()
            
            result = analyzer.analyze_statistical_question(question)
            processing_time = time.time() - start_time
            
            if result['success']:
                print(f"\nğŸ“ å›ç­” ({processing_time:.2f}ç§’):")
                print("-" * 40)
                print(result['response'])
                print("-" * 40)
                print(f"ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³: {result['tokens_consumed']}")
                
                # å“è³ªè©•ä¾¡
                validation = validate_gguf_response(result['response'])
                if validation['score'] < 50:
                    print("âš ï¸ å›ç­”å“è³ªãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                
            else:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
            
            session_count += 1
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸­æ–­")
            break
        except Exception as e:
            print(f"âŒ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ§ª Professional Statistics Suite - GGUF Integration Demo")
    print("=" * 70)
    
    if len(sys.argv) > 1:
        if sys.argv[1] == '--interactive':
            interactive_gguf_session()
            return
        elif sys.argv[1] == '--help':
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  py -3 demo_statistical_gguf.py           # ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ")
            print("  py -3 demo_statistical_gguf.py --interactive  # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰")
            print("  py -3 demo_statistical_gguf.py --help         # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º")
            return
    
    # ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    success = demonstrate_gguf_integration()
    
    if success:
        print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("   - ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰: py -3 demo_statistical_gguf.py --interactive")
        print("   - ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ: py -3 test_gguf_integration.py")
        print("   - ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: py -3 test_gguf_mock.py")
    else:
        print("\nğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:")
        print("   1. llama-cpp-python ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install llama-cpp-python")
        print("   2. GGUFãƒ¢ãƒ‡ãƒ«é…ç½®: ./models/your-model.gguf")
        print("   3. ç’°å¢ƒå¤‰æ•°è¨­å®š: set GGUF_MODEL_PATH=path/to/model.gguf")

if __name__ == '__main__':
    main()