'''
# Interactive AI Analysis App (Streamlit)
# å¯¾è©±å‹AIåˆ†æã‚¢ãƒ—ãƒª

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from ai_integration import analyze_with_ai, get_available_models

st.set_page_config(page_title="å¯¾è©±å‹AIçµ±è¨ˆåˆ†æ", layout="wide")

st.title("ğŸ¤– å¯¾è©±å‹AIçµ±è¨ˆåˆ†æ")
st.caption("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ã€è‡ªç„¶è¨€èªã§AIã«åˆ†æã‚’ä¾é ¼ã§ãã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ --- #
st.sidebar.header("è¨­å®š")

uploaded_file = st.sidebar.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

if uploaded_file is not None:
    try:
        df = pd.read_csv(uploaded_file)
        st.session_state.df = df
        st.sidebar.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼")
        st.sidebar.dataframe(df.head())
    except Exception as e:
        st.sidebar.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
available_models = get_available_models()

provider = st.sidebar.selectbox(
    "LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
    options=list(available_models.keys()),
    index=0
)

model = st.sidebar.selectbox(
    "ãƒ¢ãƒ‡ãƒ«",
    options=available_models.get(provider, []),
    index=0
)

enable_rag = st.sidebar.toggle("RAG (çŸ¥è­˜ãƒ™ãƒ¼ã‚¹) ã‚’æœ‰åŠ¹åŒ–", value=True)
enable_correction = st.sidebar.toggle("è‡ªå·±ä¿®æ­£ã‚’æœ‰åŠ¹åŒ–", value=True)

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ --- #

if 'messages' not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "code" in message:
            st.code(message["code"], language="python")
        if "output" in message:
            st.text(message["output"])
        if "fig" in message:
            st.pyplot(message["fig"])

if prompt := st.chat_input("åˆ†æã—ãŸã„å†…å®¹ã‚’ã©ã†ã (ä¾‹: Aåˆ—ã¨Båˆ—ã®ç›¸é–¢ã‚’èª¿ã¹ã¦)"):
    if 'df' not in st.session_state:
        st.error("ã¾ãšCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("AIãŒåˆ†æä¸­..."):
                result = analyze_with_ai(
                    query=prompt,
                    data=st.session_state.df,
                    provider=provider,
                    model=model,
                    enable_rag=enable_rag,
                    enable_correction=enable_correction
                )

            if result["success"]:
                st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                response_content = f"åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: `{result.get('provider', 'N/A')}`, ãƒ¢ãƒ‡ãƒ«: `{result.get('model', 'N/A')}`"
                st.markdown(response_content)
                
                message = {"role": "assistant", "content": response_content}

                if result.get("extracted_code"):
                    st.code(result["extracted_code"], language="python")
                    message["code"] = result["extracted_code"]
                
                exec_res = result.get("execution_result", {})
                if exec_res.get("output"):
                    st.text(exec_res["output"])
                    message["output"] = exec_res["output"]
                
                # Streamlitã§ã¯matplotlibã®figureã‚’ç›´æ¥æ‰±ã†
                # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªpyplotã®çŠ¶æ…‹ã‹ã‚‰figureã‚’å–å¾—ã—ã¦è¡¨ç¤º
                figs = [plt.figure(n) for n in plt.get_fignums()]
                for i, fig in enumerate(figs):
                    st.pyplot(fig)
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã™ã‚‹ãŸã‚ã«figureã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã§ããªã„ã®ã§ã€
                    # ã“ã“ã§ã¯å˜ç´”ã«è¡¨ç¤ºã™ã‚‹ã ã‘ã«ã™ã‚‹ã€‚
                    # å¿…è¦ã§ã‚ã‚Œã°BytesIOã«ä¿å­˜ã™ã‚‹ãªã©ã®å·¥å¤«ãŒå¿…è¦ã€‚
                
'''
